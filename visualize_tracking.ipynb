{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](./table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Bayes Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#format the book\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/jkuck/research/rotation3/Kalman-and-Bayesian-Filters-in-Python\")\n",
    "import book_format\n",
    "book_format.set_style()\n",
    "import kf_book.book_plots as book_plots\n",
    "from kf_book.book_plots import figsize, set_figsize\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22199317109\n",
      "0.870732306177\n",
      "0.206719155339\n",
      "0.918610907938\n",
      "0.488411188795\n",
      "BASE_EMISSION_PROBABILITIES[0]: [[0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.034 0.    0.    0.013 0.    0.954 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.006 0.    0.    0.    0.    0.006 0.    0.    0.    0.    0.    0.    0.    0.    0.987 0.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
      " [0.025 0.    0.    0.    0.    0.    0.047 0.928 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.105 0.135 0.    0.    0.76  0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.997 0.003 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.895 0.    0.    0.    0.    0.    0.    0.    0.105 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.015 0.    0.    0.    0.    0.    0.    0.    0.    0.047 0.    0.    0.    0.938]]\n",
      "all_measurements_by_time:\n",
      "[[(16,), (18,), (19,), (16,), (19,), (5,), (19,), (5,), (7,), (5,), (17,), (5,), (5,), (7,), (16,), (16,), (16,), (15,), (5,), (17,)], [(9,), (12,), (5,), (18,), (5,), (5,), (5,), (5,), (0,), (18,), (0,), (9,), (19,), (16,), (17,), (17,), (18,), (9,), (19,), (16,)], [(7,), (5,), (8,), (16,), (8,), (14,), (8,), (16,), (18,), (8,), (15,), (5,), (14,), (18,), (18,), (18,), (16,), (8,), (14,), (16,)], [(16,), (16,), (17,), (8,), (17,), (18,), (17,), (0,), (8,), (8,), (19,), (19,), (18,), (15,), (19,), (19,), (8,), (19,), (18,), (9,)], [(14,), (9,), (5,), (19,), (5,), (8,), (5,), (19,), (19,), (9,), (0,), (16,), (19,), (16,), (19,), (19,), (19,), (15,), (19,), (19,)]]\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('resized prior initialized with max =', 0.11436021370927073, 'at index', 127, 'resized_prior.shape:', (20, 20))\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n",
      "('check prior initialized with max =', 0.11436021370927073, 'at index', 127)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(particle_set) before grouping particles: 10\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n",
      "len(particle_set) after grouping particles: 1\n",
      "len(particle_set) before grouping particles: 10\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n",
      "len(particle_set) after grouping particles: 1\n",
      "len(particle_set) before grouping particles: 10\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n",
      "len(particle_set) after grouping particles: 1\n",
      "len(particle_set) before grouping particles: 10\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n",
      "len(particle_set) after grouping particles: 1\n",
      "len(particle_set) before grouping particles: 10\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n",
      "len(particle_set) after grouping particles: 2\n",
      "most_probable_particle.importance_weight: 0.1\n",
      "most_probable_particle.log_importance_weight_normalization: -197.1961924180704\n",
      "most probable particle log_prob: -199.49877751106445\n",
      "most probable particle prob: 2.284450649384989e-87\n",
      "get_gt_likelihood called\n",
      "-2.9470484692578998\n",
      "-3.3404885537751072\n",
      "-2.5300215629087575\n",
      "-2.3269320799355047\n",
      "-2.5300215629087575\n",
      "-4.4014202172772405\n",
      "-2.5300215629087575\n",
      "-5.7292083866463415\n",
      "-3.6653434226687978\n",
      "-3.044939502262701\n",
      "-2.778154545346986\n",
      "-3.8096529890120134\n",
      "-3.335037124289567\n",
      "-2.2602370163601235\n",
      "-3.509226312036628\n",
      "-3.509226312036628\n",
      "-2.3269320799355047\n",
      "-3.107189648828089\n",
      "-3.335037124289567\n",
      "-4.188024038855721\n",
      "ground truth, log_prob_of_all_targets = -65.20416251154069\n"
     ]
    }
   ],
   "source": [
    "# set HIDDEN_STATE_NOT_IN_PRIOR = True in get_parameters_and_data_targets_identical_plus_noise\n",
    "# this seems to be important to make the problem more challenging\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(5)\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "\n",
    "\n",
    "num_time_steps = 5\n",
    "# hidden_state_space = np.array((4))\n",
    "# observed_state_space = np.array((20))\n",
    "state_space = np.array((20,20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 20\n",
    "\n",
    "N_PARTICLES = 10\n",
    "use_group_particles = True\n",
    "# method = 'exact_sampling'\n",
    "method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise_GOODEXAMPLE(num_time_steps,\\\n",
    "    state_space, measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\n",
    "#     measurement_space, 1, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/14571090/ipython-redirecting-output-of-a-python-script-to-a-file-like-bash\n",
    "    context manager for reditrecting stdout/err to files\n",
    "    \"\"\"\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set HIDDEN_STATE_NOT_IN_PRIOR = True in get_parameters_and_data_targets_identical_plus_noise\n",
    "# this seems to be important to make the problem more challenging\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(11)\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "\n",
    "\n",
    "num_time_steps = 4\n",
    "hidden_state_space = np.array((5))\n",
    "observed_state_space = np.array((20))\n",
    "state_space = np.array((5, 20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 1\n",
    "\n",
    "N_PARTICLES = 1\n",
    "use_group_particles = True\n",
    "method = 'exact_sampling'\n",
    "# method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise1(num_time_steps,\\\n",
    "    state_space, hidden_state_space, observed_state_space, measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\n",
    "#     measurement_space, 1, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/14571090/ipython-redirecting-output-of-a-python-script-to-a-file-like-bash\n",
    "    context manager for reditrecting stdout/err to files\n",
    "    \"\"\"\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set HIDDEN_STATE_NOT_IN_PRIOR = True in get_parameters_and_data_targets_identical_plus_noise\n",
    "# this seems to be important to make the problem more challenging\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "\n",
    "\n",
    "num_time_steps = 6\n",
    "state_space = np.array((20,20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 15\n",
    "\n",
    "N_PARTICLES = 100\n",
    "use_group_particles = True\n",
    "# method = 'exact_sampling'\n",
    "method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data1(num_time_steps, state_space,\\\n",
    "#     measurement_space, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/14571090/ipython-redirecting-output-of-a-python-script-to-a-file-like-bash\n",
    "    context manager for reditrecting stdout/err to files\n",
    "    \"\"\"\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same state space and measurement space.  Problem here seems to be that either the problem is \n",
    "# too easy or else we find a more probable state than the ground truth, but could check more.\n",
    "# This problem may show up if we have a hidden state and the prior is not the same over the hidden states\n",
    "# set HIDDEN_STATE_NOT_IN_PRIOR = False in get_parameters_and_data_targets_identical_plus_noise\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_time_steps = 6\n",
    "state_space = np.array((20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 10\n",
    "\n",
    "N_PARTICLES = 10\n",
    "use_group_particles = True\n",
    "method = 'exact_sampling'\n",
    "# method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data1(num_time_steps, state_space,\\\n",
    "#     measurement_space, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f4301d1f4f4b4e85fe9c054e080b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description=u'step', layout=Layout(height=u'80px', width=u'100%'), max=10), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Layout\n",
    "import plotting\n",
    "COLORMAP = plt.cm.gist_ncar\n",
    "\n",
    "\n",
    "def bar_plot(pos, x=None, ylim=(0,1), title=None, c='#30a2da',\n",
    "             **kwargs):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/kf_book/book_plots.py\n",
    "    plot the values in `pos` as a bar plot.\n",
    "    **Parameters**\n",
    "    pos : list-like\n",
    "        list of values to plot as bars\n",
    "    x : list-like, optional\n",
    "         If provided, specifies the x value for each value in pos. If not\n",
    "         provided, the first pos element is plotted at x == 0, the second\n",
    "         at 1, etc.\n",
    "    ylim : (lower, upper), default = (0,1)\n",
    "        specifies the lower and upper limits for the y-axis\n",
    "    title : str, optional\n",
    "        If specified, provides a title for the plot\n",
    "    c : color, default='#30a2da'\n",
    "        Color for the bars\n",
    "    **kwargs : keywords, optional\n",
    "        extra keyword arguments passed to ax.bar()\n",
    "    \"\"\"\n",
    "\n",
    "    ax = plt.gca()\n",
    "    if x is None:\n",
    "        x = np.arange(len(pos))\n",
    "    ax.bar(x, pos, color=c, **kwargs)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "#     plt.xticks(np.asarray(x), x)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Probability')\n",
    "    \n",
    "    \n",
    "def plot_posterior(i):\n",
    "    plt.title('Posterior')\n",
    "#     plotting.bar_plot(hallway, c='k')\n",
    "#     print(posteriors[i])\n",
    "    for target_idx in range(num_targets):\n",
    "        print(\"target_idx:\", target_idx)\n",
    "#         print(\"all_target_posteriors[target_idx][i]:\", all_target_posteriors[target_idx][i])\n",
    "#         plotting.bar_plot(all_target_posteriors[target_idx][i], ylim=(0, 1.2), c=plt.cm.cool(target_idx*50))\n",
    "#         plotting.bar_plot(all_target_posteriors[target_idx][i+1], ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "        plotting.bar_plot(np.sum(all_target_posteriors[target_idx][i+1], axis=0), ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))    \n",
    "\n",
    "#         plt.axvline(all_states[target_idx][i], lw=2, c=plt.cm.cool(target_idx*50))   \n",
    "#         plt.axvline(all_states[target_idx][i], lw=10-9*target_idx/num_targets, c=COLORMAP(target_idx/num_targets))\n",
    "        plt.axvline(all_states[target_idx][i][1] -.3 + .5*target_idx/num_targets, lw=1.5, c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "\n",
    "    \n",
    "def plot_prior(i):\n",
    "    plt.title('Prior')\n",
    "#     plotting.bar_plot(hallway, c='k')\n",
    "#     plotting.bar_plot(priors[i], ylim=(0, 1.0), c='#ff8015')\n",
    "    for target_idx in range(num_targets):\n",
    "#         print(\"all_target_priors[target_idx][i]:\", all_target_priors[target_idx][i])\n",
    "#         plotting.bar_plot(all_target_priors[target_idx][i], ylim=(0, 1.2), c=plt.cm.cool(target_idx*50))\n",
    "#         plotting.bar_plot(all_target_priors[target_idx][i], ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "        plotting.bar_plot(np.sum(all_target_priors[target_idx][i], axis=0), ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "#         plt.axvline(all_states[target_idx][i], lw=10-9*target_idx/num_targets, c=COLORMAP(target_idx/num_targets))\n",
    "        plt.axvline(all_states[target_idx][i][1] -.3 + .5*target_idx/num_targets, lw=1.5, c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "\n",
    "\n",
    "#     plt.axvline(i % STATE_SPACE.size, lw=5)    \n",
    "\n",
    "def animate_discrete_bayes(step):\n",
    "    step -= 1\n",
    "    i = step // 2    \n",
    "    if step % 2 == 0:\n",
    "        plot_prior(i)\n",
    "        print('time_idx =', i)\n",
    "    else:\n",
    "        plot_posterior(i)        \n",
    "        print('time_idx =', i)       \n",
    "        \n",
    "        \n",
    "interact(animate_discrete_bayes, step=IntSlider(value=1, max=num_time_steps*2, layout=Layout(width='100%', height='80px')));        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMISSION_PROBABILITIES[0]: [[0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.412 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.587 0.    0.    0.    0.    0.    0.    0.    0.001]\n",
      " [0.    0.    0.    0.984 0.    0.    0.    0.    0.    0.016 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.243 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.741 0.    0.    0.016 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.017 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.982 0.    0.    0.001 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.028 0.    0.972 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.178 0.    0.822 0.    0.    0.    0.   ]\n",
      " [0.    0.086 0.    0.    0.    0.    0.914 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.949 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.051 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.798 0.    0.    0.    0.202 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]]\n",
      "all_measurements_by_time:\n",
      "[[(3,), (2,), (8,), (3,), (12,), (15,), (6,), (10,), (15,), (15,)], [(10,), (1,), (15,), (17,), (4,), (15,), (3,), (10,), (4,), (12,)], [(15,), (11,), (10,), (3,), (15,), (12,), (16,), (16,), (3,), (10,)], [(10,), (12,), (10,), (7,), (7,), (14,), (10,), (12,), (7,), (10,)]]\n",
      "('prior initialized with max =', 0.0253340845924198, 'at index', 183)\n",
      "('resized prior initialized with max =', 0.0253340845924198, 'at index', 183, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.020970016805086797, 'at index', 179)\n",
      "('resized prior initialized with max =', 0.020970016805086797, 'at index', 179, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.02752645238396926, 'at index', 348)\n",
      "('resized prior initialized with max =', 0.02752645238396926, 'at index', 348, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.026579888467908222, 'at index', 188)\n",
      "('resized prior initialized with max =', 0.026579888467908222, 'at index', 188, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.028552619754207496, 'at index', 373)\n",
      "('resized prior initialized with max =', 0.028552619754207496, 'at index', 373, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.03499704071596756, 'at index', 267)\n",
      "('resized prior initialized with max =', 0.03499704071596756, 'at index', 267, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.02959486498571259, 'at index', 163)\n",
      "('resized prior initialized with max =', 0.02959486498571259, 'at index', 163, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.028924210676085367, 'at index', 131)\n",
      "('resized prior initialized with max =', 0.028924210676085367, 'at index', 131, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.026054030689009473, 'at index', 298)\n",
      "('resized prior initialized with max =', 0.026054030689009473, 'at index', 298, 'resized_prior.shape:', (20, 20))\n",
      "('prior initialized with max =', 0.02566230773365163, 'at index', 267)\n",
      "('resized prior initialized with max =', 0.02566230773365163, 'at index', 267, 'resized_prior.shape:', (20, 20))\n",
      "('check prior initialized with max =', 0.0253340845924198, 'at index', 183)\n",
      "('check prior initialized with max =', 0.020970016805086797, 'at index', 179)\n",
      "('check prior initialized with max =', 0.02752645238396926, 'at index', 348)\n",
      "('check prior initialized with max =', 0.026579888467908222, 'at index', 188)\n",
      "('check prior initialized with max =', 0.028552619754207496, 'at index', 373)\n",
      "('check prior initialized with max =', 0.03499704071596756, 'at index', 267)\n",
      "('check prior initialized with max =', 0.02959486498571259, 'at index', 163)\n",
      "('check prior initialized with max =', 0.028924210676085367, 'at index', 131)\n",
      "('check prior initialized with max =', 0.026054030689009473, 'at index', 298)\n",
      "('check prior initialized with max =', 0.02566230773365163, 'at index', 267)\n",
      "len(particle_set) before grouping particles: 500\n",
      "extra_idx: 0 len(grouped_particle_set): 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49665566b541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# with io.capture_output() as captured:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mall_target_posteriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_target_priors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_probable_particle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_tracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_measurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerative_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_particles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_PARTICLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_group_particles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_group_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"most_probable_particle.importance_weight:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_probable_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jkuck/tracking_research/muti_target_discrete_bayes/perform_tracking.pyc\u001b[0m in \u001b[0;36mrun_tracking\u001b[0;34m(all_measurements, tracking_method, generative_parameters, n_particles, use_group_particles)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mextra_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"extra_idx:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"len(grouped_particle_set):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_particle_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0mgrouped_particle_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_particle_set\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparticle_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextra_idx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_PARTICLES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_PARTICLES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_particle_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN_PARTICLES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jkuck/tracking_research/muti_target_discrete_bayes/perform_tracking.pyc\u001b[0m in \u001b[0;36mgroup_particles\u001b[0;34m(particle_set, verbose)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mold_particle_added_to_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_particle_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_particle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_particle_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mparticles_are_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_particle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'particles are similar!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jkuck/tracking_research/muti_target_discrete_bayes/perform_tracking.pyc\u001b[0m in \u001b[0;36mparticles_are_similar\u001b[0;34m(particleA, particleB, distance_threshold)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticleA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticleB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m             \u001b[0mcost_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_distance_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;31m#2. find the minimum cost matching between particle A's targets and particle B's targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jkuck/tracking_research/muti_target_discrete_bayes/perform_tracking.pyc\u001b[0m in \u001b[0;36mdistribution_distance_metric\u001b[0;34m(distributionA, distributionB)\u001b[0m\n\u001b[1;32m    764\u001b[0m     '''\n\u001b[1;32m    765\u001b[0m     \u001b[0;31m# return np.max(np.abs(distributionA-distributionB)/np.maximum(distributionA,distributionB))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributionA\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdistributionB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmin_cost_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_time_steps = 4\n",
    "state_space = np.array((20,20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 10\n",
    "\n",
    "N_PARTICLES = 500\n",
    "use_group_particles = True\n",
    "# method = 'exact_sampling'\n",
    "method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    " * [1] D. Fox, W. Burgard, and S. Thrun. \"Monte carlo localization: Efficient position estimation for mobile robots.\" In *Journal of Artifical Intelligence Research*, 1999.\n",
    " \n",
    " http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/fox99a-html/jair-localize.html\n",
    "\n",
    "\n",
    " * [2] Dieter Fox, et. al. \"Bayesian Filters for Location Estimation\". In *IEEE Pervasive Computing*, September 2003.\n",
    " \n",
    " http://swarmlab.unimaas.nl/wp-content/uploads/2012/07/fox2003bayesian.pdf\n",
    " \n",
    " \n",
    " * [3] Sebastian Thrun. \"Artificial Intelligence for Robotics\".\n",
    " \n",
    " https://www.udacity.com/course/cs373\n",
    " \n",
    " \n",
    " * [4] Khan Acadamy. \"Introduction to the Convolution\"\n",
    " \n",
    " https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution\n",
    " \n",
    " \n",
    "* [5] Wikipedia. \"Convolution\"\n",
    "\n",
    " http://en.wikipedia.org/wiki/Convolution\n",
    "\n",
    "* [6] Wikipedia. \"Law of total probability\"\n",
    "\n",
    "  http://en.wikipedia.org/wiki/Law_of_total_probability\n",
    "  \n",
    "* [7] Wikipedia. \"Time Evolution\"\n",
    "\n",
    " https://en.wikipedia.org/wiki/Time_evolution\n",
    " \n",
    "* [8] We need to rethink how we teach statistics from the ground up\n",
    " \n",
    " http://www.statslife.org.uk/opinion/2405-we-need-to-rethink-how-we-teach-statistics-from-the-ground-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(all_target_posteriors[0][4][1]))\n",
    "# print(np.sum(all_target_posteriors[0][4][2]))\n",
    "# print(np.sum(all_target_posteriors[0][4][3]))\n",
    "# print(np.sum(all_target_posteriors[0][4][4]))\n",
    "# print(np.sum(all_target_posteriors[0][4][5]))\n",
    "# print(np.sum(all_target_posteriors[0][4][6]))\n",
    "# print(np.sum(all_target_posteriors[0][4][7]))\n",
    "# print(np.sum(all_target_posteriors[0][4][8]))\n",
    "# print(np.sum(all_target_posteriors[0][4][9]))\n",
    "\n",
    "\n",
    "# all_target_posteriors[0][4][2]\n",
    "# print(all_target_posteriors[0][4])\n",
    "# np.sum(all_target_posteriors[0][4], axis=0)\n",
    "\n",
    "all_states[0][3][1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
