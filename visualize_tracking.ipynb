{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](./table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Bayes Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#format the book\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/jkuck/research/rotation3/Kalman-and-Bayesian-Filters-in-Python\")\n",
    "import book_format\n",
    "book_format.set_style()\n",
    "import kf_book.book_plots as book_plots\n",
    "from kf_book.book_plots import figsize, set_figsize\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.435994902142\n",
      "0.0259262318279\n",
      "0.549662477879\n",
      "0.435322392618\n",
      "0.420367802087\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (20,1) could not be broadcast to indexing result of shape (1,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d7f670a62a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# method = 'MHT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mall_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_measurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters_and_data_targets_identical_plus_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_space\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmeasurement_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkov_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#     measurement_space, 1, num_targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jkuck/tracking_research/rbpf_fireworks/generate_data.pyc\u001b[0m in \u001b[0;36mget_parameters_and_data_targets_identical_plus_noise\u001b[0;34m(num_time_steps, state_space, measurement_space, markov_order, num_targets)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# print \"BASE_INITIAL_STATE_PROBABILITIES[:, cur_state_index].shape:\", BASE_INITIAL_STATE_PROBABILITIES[:, cur_state_index].shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# print \"cur_initial_state_probs.shape:\", cur_initial_state_probs.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mBASE_INITIAL_STATE_PROBABILITIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_state_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_initial_state_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mBASE_INITIAL_STATE_PROBABILITIES\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_INITIAL_STATE_PROBABILITIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (20,1) could not be broadcast to indexing result of shape (1,4)"
     ]
    }
   ],
   "source": [
    "# set HIDDEN_STATE_NOT_IN_PRIOR = True in get_parameters_and_data_targets_identical_plus_noise\n",
    "# this seems to be important to make the problem more challenging\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(2)\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "\n",
    "\n",
    "num_time_steps = 4\n",
    "hidden_state_space = np.array((4))\n",
    "observed_state_space = np.array((20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 15\n",
    "\n",
    "N_PARTICLES = 10\n",
    "use_group_particles = True\n",
    "method = 'exact_sampling'\n",
    "# method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise(num_time_steps,\\\n",
    "    hidden_state_space, observed_state_space, measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\n",
    "#     measurement_space, 1, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/14571090/ipython-redirecting-output-of-a-python-script-to-a-file-like-bash\n",
    "    context manager for reditrecting stdout/err to files\n",
    "    \"\"\"\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set HIDDEN_STATE_NOT_IN_PRIOR = True in get_parameters_and_data_targets_identical_plus_noise\n",
    "# this seems to be important to make the problem more challenging\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "print(np.random.rand())\n",
    "\n",
    "\n",
    "num_time_steps = 6\n",
    "state_space = np.array((20,20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 15\n",
    "\n",
    "N_PARTICLES = 100\n",
    "use_group_particles = True\n",
    "# method = 'exact_sampling'\n",
    "method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data1(num_time_steps, state_space,\\\n",
    "#     measurement_space, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/14571090/ipython-redirecting-output-of-a-python-script-to-a-file-like-bash\n",
    "    context manager for reditrecting stdout/err to files\n",
    "    \"\"\"\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same state space and measurement space.  Problem here seems to be that either the problem is \n",
    "# too easy or else we find a more probable state than the ground truth, but could check more.\n",
    "# This problem may show up if we have a hidden state and the prior is not the same over the hidden states\n",
    "# set HIDDEN_STATE_NOT_IN_PRIOR = False in get_parameters_and_data_targets_identical_plus_noise\n",
    "\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_time_steps = 6\n",
    "state_space = np.array((20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 10\n",
    "\n",
    "N_PARTICLES = 10\n",
    "use_group_particles = True\n",
    "method = 'exact_sampling'\n",
    "# method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data_targets_identical_plus_noise(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "# (all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data1(num_time_steps, state_space,\\\n",
    "#     measurement_space, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "# with redirect_output(\"my_output.txt\"):\n",
    "#     print(captured)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Layout\n",
    "import plotting\n",
    "COLORMAP = plt.cm.gist_ncar\n",
    "\n",
    "\n",
    "def bar_plot(pos, x=None, ylim=(0,1), title=None, c='#30a2da',\n",
    "             **kwargs):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/kf_book/book_plots.py\n",
    "    plot the values in `pos` as a bar plot.\n",
    "    **Parameters**\n",
    "    pos : list-like\n",
    "        list of values to plot as bars\n",
    "    x : list-like, optional\n",
    "         If provided, specifies the x value for each value in pos. If not\n",
    "         provided, the first pos element is plotted at x == 0, the second\n",
    "         at 1, etc.\n",
    "    ylim : (lower, upper), default = (0,1)\n",
    "        specifies the lower and upper limits for the y-axis\n",
    "    title : str, optional\n",
    "        If specified, provides a title for the plot\n",
    "    c : color, default='#30a2da'\n",
    "        Color for the bars\n",
    "    **kwargs : keywords, optional\n",
    "        extra keyword arguments passed to ax.bar()\n",
    "    \"\"\"\n",
    "\n",
    "    ax = plt.gca()\n",
    "    if x is None:\n",
    "        x = np.arange(len(pos))\n",
    "    ax.bar(x, pos, color=c, **kwargs)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "#     plt.xticks(np.asarray(x), x)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Probability')\n",
    "    \n",
    "    \n",
    "def plot_posterior(i):\n",
    "    plt.title('Posterior')\n",
    "#     plotting.bar_plot(hallway, c='k')\n",
    "#     print(posteriors[i])\n",
    "    for target_idx in range(num_targets):\n",
    "        print(\"target_idx:\", target_idx)\n",
    "#         print(\"all_target_posteriors[target_idx][i]:\", all_target_posteriors[target_idx][i])\n",
    "#         plotting.bar_plot(all_target_posteriors[target_idx][i], ylim=(0, 1.2), c=plt.cm.cool(target_idx*50))\n",
    "#         plotting.bar_plot(all_target_posteriors[target_idx][i+1], ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "        plotting.bar_plot(np.sum(all_target_posteriors[target_idx][i+1], axis=0), ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))    \n",
    "\n",
    "#         plt.axvline(all_states[target_idx][i], lw=2, c=plt.cm.cool(target_idx*50))   \n",
    "#         plt.axvline(all_states[target_idx][i], lw=10-9*target_idx/num_targets, c=COLORMAP(target_idx/num_targets))\n",
    "        plt.axvline(all_states[target_idx][i][1] -.3 + .5*target_idx/num_targets, lw=1.5, c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "\n",
    "    \n",
    "def plot_prior(i):\n",
    "    plt.title('Prior')\n",
    "#     plotting.bar_plot(hallway, c='k')\n",
    "#     plotting.bar_plot(priors[i], ylim=(0, 1.0), c='#ff8015')\n",
    "    for target_idx in range(num_targets):\n",
    "#         print(\"all_target_priors[target_idx][i]:\", all_target_priors[target_idx][i])\n",
    "#         plotting.bar_plot(all_target_priors[target_idx][i], ylim=(0, 1.2), c=plt.cm.cool(target_idx*50))\n",
    "#         plotting.bar_plot(all_target_priors[target_idx][i], ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "        plotting.bar_plot(np.sum(all_target_priors[target_idx][i], axis=0), ylim=(0, 1.2), c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "#         plt.axvline(all_states[target_idx][i], lw=10-9*target_idx/num_targets, c=COLORMAP(target_idx/num_targets))\n",
    "        plt.axvline(all_states[target_idx][i][1] -.3 + .5*target_idx/num_targets, lw=1.5, c=COLORMAP(target_idx/num_targets))\n",
    "\n",
    "\n",
    "\n",
    "#     plt.axvline(i % STATE_SPACE.size, lw=5)    \n",
    "\n",
    "def animate_discrete_bayes(step):\n",
    "    step -= 1\n",
    "    i = step // 2    \n",
    "    if step % 2 == 0:\n",
    "        plot_prior(i)\n",
    "        print('time_idx =', i)\n",
    "    else:\n",
    "        plot_posterior(i)        \n",
    "        print('time_idx =', i)       \n",
    "        \n",
    "        \n",
    "interact(animate_discrete_bayes, step=IntSlider(value=1, max=num_time_steps*2, layout=Layout(width='100%', height='80px')));        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "import perform_tracking\n",
    "reload(perform_tracking)\n",
    "import generate_data\n",
    "reload(generate_data)\n",
    "import plotting\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_time_steps = 4\n",
    "state_space = np.array((20,20))\n",
    "measurement_space = np.array((20))\n",
    "markov_order = 1\n",
    "num_targets = 10\n",
    "\n",
    "N_PARTICLES = 500\n",
    "use_group_particles = True\n",
    "# method = 'exact_sampling'\n",
    "method = 'MHT'\n",
    "\n",
    "(all_states, all_measurements, gen_params) = generate_data.get_parameters_and_data(num_time_steps, state_space,\\\n",
    "    measurement_space, markov_order, num_targets)\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "(all_target_posteriors, all_target_priors, most_probable_particle) = perform_tracking.run_tracking(all_measurements, tracking_method=method, generative_parameters=gen_params, n_particles=N_PARTICLES, use_group_particles=use_group_particles)\n",
    "\n",
    "print(\"most_probable_particle.importance_weight:\", most_probable_particle.importance_weight)\n",
    "print(\"most_probable_particle.log_importance_weight_normalization:\", most_probable_particle.log_importance_weight_normalization)\n",
    "print(\"most probable particle log_prob:\", most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight))\n",
    "print(\"most probable particle prob:\", np.exp(most_probable_particle.log_importance_weight_normalization + np.log(most_probable_particle.importance_weight)))\n",
    "\n",
    "print(\"ground truth, log_prob_of_all_targets =\", perform_tracking.get_gt_likelihood(gen_params, all_measurements))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    " * [1] D. Fox, W. Burgard, and S. Thrun. \"Monte carlo localization: Efficient position estimation for mobile robots.\" In *Journal of Artifical Intelligence Research*, 1999.\n",
    " \n",
    " http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/fox99a-html/jair-localize.html\n",
    "\n",
    "\n",
    " * [2] Dieter Fox, et. al. \"Bayesian Filters for Location Estimation\". In *IEEE Pervasive Computing*, September 2003.\n",
    " \n",
    " http://swarmlab.unimaas.nl/wp-content/uploads/2012/07/fox2003bayesian.pdf\n",
    " \n",
    " \n",
    " * [3] Sebastian Thrun. \"Artificial Intelligence for Robotics\".\n",
    " \n",
    " https://www.udacity.com/course/cs373\n",
    " \n",
    " \n",
    " * [4] Khan Acadamy. \"Introduction to the Convolution\"\n",
    " \n",
    " https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution\n",
    " \n",
    " \n",
    "* [5] Wikipedia. \"Convolution\"\n",
    "\n",
    " http://en.wikipedia.org/wiki/Convolution\n",
    "\n",
    "* [6] Wikipedia. \"Law of total probability\"\n",
    "\n",
    "  http://en.wikipedia.org/wiki/Law_of_total_probability\n",
    "  \n",
    "* [7] Wikipedia. \"Time Evolution\"\n",
    "\n",
    " https://en.wikipedia.org/wiki/Time_evolution\n",
    " \n",
    "* [8] We need to rethink how we teach statistics from the ground up\n",
    " \n",
    " http://www.statslife.org.uk/opinion/2405-we-need-to-rethink-how-we-teach-statistics-from-the-ground-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(all_target_posteriors[0][4][1]))\n",
    "# print(np.sum(all_target_posteriors[0][4][2]))\n",
    "# print(np.sum(all_target_posteriors[0][4][3]))\n",
    "# print(np.sum(all_target_posteriors[0][4][4]))\n",
    "# print(np.sum(all_target_posteriors[0][4][5]))\n",
    "# print(np.sum(all_target_posteriors[0][4][6]))\n",
    "# print(np.sum(all_target_posteriors[0][4][7]))\n",
    "# print(np.sum(all_target_posteriors[0][4][8]))\n",
    "# print(np.sum(all_target_posteriors[0][4][9]))\n",
    "\n",
    "\n",
    "# all_target_posteriors[0][4][2]\n",
    "# print(all_target_posteriors[0][4])\n",
    "# np.sum(all_target_posteriors[0][4], axis=0)\n",
    "\n",
    "all_states[0][3][1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
